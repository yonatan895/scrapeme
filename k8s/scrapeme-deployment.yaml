# ScrapeMe main application deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scrapeme-app
  namespace: scrapeme
  labels:
    app.kubernetes.io/name: scrapeme
    app.kubernetes.io/component: scraper
    app.kubernetes.io/part-of: scrapeme
    app.kubernetes.io/version: "2.0.0"
spec:
  replicas: 3  # Start with 3 replicas for high availability
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 2
  selector:
    matchLabels:
      app: scrapeme
      component: scraper
  template:
    metadata:
      labels:
        app: scrapeme
        component: scraper
        app.kubernetes.io/name: scrapeme
        app.kubernetes.io/component: scraper
      annotations:
        # Prometheus scraping configuration
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
        # Configuration checksum for rolling updates
        checksum/config: "{{ include 'scrapeme.configChecksum' . }}"
    spec:
      serviceAccountName: scrapeme-app
      # Security context for the entire pod
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001  # matches Dockerfile USER
        runAsGroup: 10001
        fsGroup: 10001
        seccompProfile:
          type: RuntimeDefault
      # DNS configuration for better service discovery
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
        - name: ndots
          value: "2"
        - name: edns0
      containers:
      - name: scrapeme
        # NOTE: Update this image reference to your registry
        image: ghcr.io/yonatan895/scrapeme:latest
        imagePullPolicy: IfNotPresent  # Use Always for :latest tag in production
        ports:
        - name: metrics
          containerPort: 9090
          protocol: TCP
        # Environment variables
        env:
        # Basic application configuration
        - name: METRICS_PORT
          value: "9090"
        - name: LOG_LEVEL
          value: "INFO"
        - name: ENABLE_POOLING
          value: "true"
        - name: MAX_WORKERS
          value: "4"
        # Selenium Grid configuration
        - name: REMOTE_URL
          value: "http://selenium-hub:4444"
        # Secrets from Secret object
        - name: SITE_USERNAME
          valueFrom:
            secretKeyRef:
              name: scrapeme-secrets
              key: SITE_USERNAME
        - name: SITE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: scrapeme-secrets
              key: SITE_PASSWORD
        # Pod information
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        # Application arguments
        args:
        - --config
        - /app/config/sites.yaml
        - --browser
        - chrome
        - --headless
        - --enable-pooling
        - --remote-url
        - http://selenium-hub:4444
        - --metrics-port
        - "9090"
        - --json-logs
        - --daemon
        - --artifact-dir
        - /app/artifacts
        - --max-workers
        - "4"
        # Volume mounts
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: artifacts
          mountPath: /app/artifacts
        - name: results
          mountPath: /app/results
        - name: tmp
          mountPath: /tmp
        # Health checks
        livenessProbe:
          httpGet:
            path: /healthz
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
          successThreshold: 1
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 15
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        # Startup probe for slow initialization
        startupProbe:
          httpGet:
            path: /healthz
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 10  # Allow 100 seconds for startup
          successThreshold: 1
        # Resource management
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        # Security context for container
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false  # Application needs to write logs/artifacts
          runAsNonRoot: true
          runAsUser: 10001
          capabilities:
            drop:
            - ALL
        # Lifecycle hooks
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - "kill -TERM 1; sleep 15"  # Graceful shutdown
      # Pod volumes
      volumes:
      - name: config
        configMap:
          name: scrapeme-config
          items:
          - key: sites.yaml
            path: sites.yaml
      - name: artifacts
        persistentVolumeClaim:
          claimName: scrapeme-artifacts-pvc
      - name: results
        persistentVolumeClaim:
          claimName: scrapeme-results-pvc
      - name: tmp
        emptyDir:
          sizeLimit: 1Gi
      # Image pull secrets (uncomment if using private registry)
      # imagePullSecrets:
      # - name: docker-registry-secret
      # Node selection and affinity
      affinity:
        # Prefer to spread pods across different nodes
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - scrapeme
              topologyKey: kubernetes.io/hostname
        # Prefer nodes with more CPU/memory
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values:
                - compute-optimized
                - general-purpose
      # Tolerations for dedicated nodes (optional)
      # tolerations:
      # - key: scrapeme
      #   operator: Equal
      #   value: "true"
      #   effect: NoSchedule
      # Graceful termination
      terminationGracePeriodSeconds: 60
      # Restart policy
      restartPolicy: Always

---
# Pod Disruption Budget for main application
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: scrapeme-app-pdb
  namespace: scrapeme
  labels:
    app.kubernetes.io/name: scrapeme
    app.kubernetes.io/component: scraper
spec:
  minAvailable: 2  # Ensure at least 2 pods are always available
  selector:
    matchLabels:
      app: scrapeme
      component: scraper
